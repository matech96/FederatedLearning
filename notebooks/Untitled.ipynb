{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "from comet_ml import Experiment, OfflineExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple, List\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from syftutils.datasets import get_dataset_items_at\n",
    "\n",
    "from FFL.TorchFederatedLearner import TorchFederatedLearner, TorchFederatedLearnerConfig\n",
    "\n",
    "\n",
    "class TorchFederatedLearnerMNISTConfig(TorchFederatedLearnerConfig):\n",
    "    IS_IID_DATA: bool = True  # If true, the data is split random amongs clients. If false, the client have different digits.\n",
    "\n",
    "\n",
    "class TorchFederatedLearnerMNIST(TorchFederatedLearner):\n",
    "    def __init__(\n",
    "        self, experiment: Experiment, config: TorchFederatedLearnerMNISTConfig\n",
    "    ) -> None:\n",
    "        \"\"\"Initialises the training.\n",
    "\n",
    "        Arguments:\n",
    "            experiment {Experiment} -- Comet.ml experiment object for online logging.\n",
    "            config {TorchFederatedLearnerMNISTConfig} -- Training configuration description.\n",
    "        \"\"\"\n",
    "        super().__init__(experiment, config)\n",
    "        self.config = config  # Purly to help intellisense\n",
    "\n",
    "    def load_data(self) -> Tuple[List[th.utils.data.DataLoader], th.utils.data.DataLoader]:\n",
    "        logging.info(\"MNIST data loading ...\")\n",
    "        minist_train_ds, mnist_test_ds = self.__get_mnist()\n",
    "        logging.info(\"MNIST data loaded.\")\n",
    "\n",
    "        logging.info(\"Data distributing ...\")\n",
    "        n_training_samples = len(minist_train_ds)\n",
    "        logging.info(\"Number of training samples: {n_training_samples}\")\n",
    "        if self.config.IS_IID_DATA:\n",
    "            indices = np.arange(n_training_samples).reshape(self.config.N_CLIENTS, -1)\n",
    "            indices = indices.tolist()\n",
    "            # federated_train_dataset = minist_train_ds.federate(\n",
    "            #     self.clients\n",
    "            # )  # TODO HARD get list of index samples instead\n",
    "        else:\n",
    "            indices = self.__distribute_data_non_IID(\n",
    "                minist_train_ds\n",
    "            )\n",
    "\n",
    "        # TODO HARD use list of DataLoader and indices with sampler\n",
    "        train_loader_list = []\n",
    "        for idx in indices:\n",
    "            sampler = th.utils.data.sampler.SubsetRandomSampler(idx)\n",
    "            loader = th.utils.data.DataLoader(\n",
    "                dataset=minist_train_ds,\n",
    "                batch_size=self.config.BATCH_SIZE,\n",
    "                num_workers=self.config.DL_N_WORKER,\n",
    "                sampler=sampler,\n",
    "            )\n",
    "            train_loader_list.append(loader)\n",
    "        # federated_train_loader = sy.FederatedDataLoader(\n",
    "        #     federated_train_dataset,\n",
    "        #     batch_size=self.config.BATCH_SIZE,\n",
    "        #     shuffle=True,\n",
    "        #     num_workers=self.config.DL_N_WORKER,\n",
    "        #     pin_memory=True,\n",
    "        # )\n",
    "        logging.info(\"Data distributed.\")\n",
    "\n",
    "        test_loader = th.utils.data.DataLoader(\n",
    "            mnist_test_ds,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=self.config.DL_N_WORKER,\n",
    "        )\n",
    "\n",
    "        return train_loader_list, test_loader\n",
    "\n",
    "    def __get_mnist(self):\n",
    "        minist_train_ds = datasets.MNIST(\n",
    "            \"../data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        )\n",
    "        mnist_test_ds = datasets.MNIST(\n",
    "            \"../data\",\n",
    "            train=False,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        )\n",
    "        return minist_train_ds, mnist_test_ds\n",
    "\n",
    "    def __distribute_data_non_IID(self, minist_train_ds):\n",
    "        digit_sort_idx = np.concatenate(\n",
    "            [np.where(minist_train_ds.targets == i)[0] for i in range(10)]\n",
    "        )\n",
    "        digit_sort_idx = digit_sort_idx.reshape(2 * self.config.N_CLIENTS, -1)\n",
    "        np.random.shuffle(digit_sort_idx)\n",
    "        indices = [\n",
    "            digit_sort_idx[i : i + 2,].flatten()\n",
    "            for i in range(0, 2 * self.config.N_CLIENTS, 2)\n",
    "        ]\n",
    "        return indices\n",
    "        # TODO return idices and remove the rest\n",
    "        # dss = []\n",
    "        # for idx, c in zip(indices, self.clients):\n",
    "        #     data, target = get_dataset_items_at(minist_train_ds, idx)\n",
    "        #     dss.append(sy.BaseDataset(data.send(c), target.send(c)))\n",
    "\n",
    "        # federated_train_dataset = sy.FederatedDataset(dss)\n",
    "        # return federated_train_dataset\n",
    "\n",
    "    def build_model(self) -> nn.Module:\n",
    "        return Net()\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 64, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4 * 4 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary:\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     url: [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     sys.cpu.percent.01 [15]       : (1.0, 40.0)\n",
      "COMET INFO:     sys.cpu.percent.02 [15]       : (1.6, 23.8)\n",
      "COMET INFO:     sys.cpu.percent.03 [15]       : (1.5, 26.9)\n",
      "COMET INFO:     sys.cpu.percent.04 [15]       : (1.0, 25.4)\n",
      "COMET INFO:     sys.cpu.percent.avg [15]      : (2.375, 29.025)\n",
      "COMET INFO:     sys.gpu.0.free_memory [12]    : (4238999552.0, 4238999552.0)\n",
      "COMET INFO:     sys.gpu.0.gpu_utilization [12]: (0.0, 0.0)\n",
      "COMET INFO:     sys.gpu.0.total_memory        : (4238999552.0, 4238999552.0)\n",
      "COMET INFO:     sys.gpu.0.used_memory [12]    : (0.0, 0.0)\n",
      "COMET INFO:     sys.load.avg [15]             : (0.03, 0.97)\n",
      "COMET INFO:     sys.ram.total [15]            : (8326709248.0, 8326709248.0)\n",
      "COMET INFO:     sys.ram.used [15]             : (1869348864.0, 2014724096.0)\n",
      "COMET INFO:   Other [count]:\n",
      "COMET INFO:     offline_experiment: True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     git-patch: 1\n",
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload ./tmp/725efecc0ba0489c97b065b73bc301f2.zip\n",
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "lr = TorchFederatedLearnerMNIST(OfflineExperiment(offline_directory='./tmp'), TorchFederatedLearnerMNISTConfig(IS_IID_DATA=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, te = lr.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data, target = next(iter(tr[1]))\n",
    "plt.imshow(data[0, 0, ])\n",
    "print(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_ in list(range(10)):\n",
    "    if f_ not in target.numpy().flatten().tolist():\n",
    "        print(f_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60032"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(d) for d in tr]) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ...,   597,   598,   599],\n",
       "       [  600,   601,   602, ...,  1197,  1198,  1199],\n",
       "       [ 1200,  1201,  1202, ...,  1797,  1798,  1799],\n",
       "       ...,\n",
       "       [58200, 58201, 58202, ..., 58797, 58798, 58799],\n",
       "       [58800, 58801, 58802, ..., 59397, 59398, 59399],\n",
       "       [59400, 59401, 59402, ..., 59997, 59998, 59999]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(60000).reshape(100, -1)\n",
    "indices = indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.34 ms, total: 2.34 ms\n",
      "Wall time: 2.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l = indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.MNIST(\n",
    "            \"../data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        )\n",
    "ds.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
