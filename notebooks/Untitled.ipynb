{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import torch\n",
    "import tensorflow\n",
    "# from comet_ml import Experiment, OfflineExperiment\n",
    "from mutil.Empty import Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple, List\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from FLF.TorchFederatedLearner import TorchFederatedLearner, TorchFederatedLearnerConfig, TorchFederatedLearnerTechnicalConfig\n",
    "from FLF.TorchFederatedLearnerEMNIST import TorchFederatedLearnerEMNIST, TorchFederatedLearnerEMNISTConfig\n",
    "\n",
    "\n",
    "# class TorchFederatedLearnerMNISTConfig(TorchFederatedLearnerConfig):\n",
    "#     IS_IID_DATA: bool = True  # If true, the data is split random amongs clients. If false, the client have different digits.\n",
    "\n",
    "\n",
    "# class TorchFederatedLearnerMNIST(TorchFederatedLearner):\n",
    "#     def __init__(\n",
    "#         self, experiment: Experiment, config: TorchFederatedLearnerMNISTConfig\n",
    "#     ) -> None:\n",
    "#         \"\"\"Initialises the training.\n",
    "\n",
    "#         Arguments:\n",
    "#             experiment {Experiment} -- Comet.ml experiment object for online logging.\n",
    "#             config {TorchFederatedLearnerMNISTConfig} -- Training configuration description.\n",
    "#         \"\"\"\n",
    "#         super().__init__(experiment, config)\n",
    "#         self.config = config  # Purly to help intellisense\n",
    "\n",
    "#     def load_data(self) -> Tuple[List[th.utils.data.DataLoader], th.utils.data.DataLoader]:\n",
    "#         logging.info(\"MNIST data loading ...\")\n",
    "#         minist_train_ds, mnist_test_ds = self.__get_mnist()\n",
    "#         logging.info(\"MNIST data loaded.\")\n",
    "\n",
    "#         logging.info(\"Data distributing ...\")\n",
    "#         n_training_samples = len(minist_train_ds)\n",
    "#         logging.info(\"Number of training samples: {n_training_samples}\")\n",
    "#         if self.config.IS_IID_DATA:\n",
    "#             indices = np.arange(n_training_samples).reshape(self.config.N_CLIENTS, -1)\n",
    "#             indices = indices.tolist()\n",
    "#             # federated_train_dataset = minist_train_ds.federate(\n",
    "#             #     self.clients\n",
    "#             # )  # TODO HARD get list of index samples instead\n",
    "#         else:\n",
    "#             indices = self.__distribute_data_non_IID(\n",
    "#                 minist_train_ds\n",
    "#             )\n",
    "\n",
    "#         # TODO HARD use list of DataLoader and indices with sampler\n",
    "#         train_loader_list = []\n",
    "#         for idx in indices:\n",
    "#             sampler = th.utils.data.sampler.SubsetRandomSampler(idx)\n",
    "#             loader = th.utils.data.DataLoader(\n",
    "#                 dataset=minist_train_ds,\n",
    "#                 batch_size=self.config.BATCH_SIZE,\n",
    "#                 num_workers=self.config.DL_N_WORKER,\n",
    "#                 sampler=sampler,\n",
    "#             )\n",
    "#             train_loader_list.append(loader)\n",
    "#         # federated_train_loader = sy.FederatedDataLoader(\n",
    "#         #     federated_train_dataset,\n",
    "#         #     batch_size=self.config.BATCH_SIZE,\n",
    "#         #     shuffle=True,\n",
    "#         #     num_workers=self.config.DL_N_WORKER,\n",
    "#         #     pin_memory=True,\n",
    "#         # )\n",
    "#         logging.info(\"Data distributed.\")\n",
    "\n",
    "#         test_loader = th.utils.data.DataLoader(\n",
    "#             mnist_test_ds,\n",
    "#             batch_size=64,\n",
    "#             shuffle=True,\n",
    "#             num_workers=self.config.DL_N_WORKER,\n",
    "#         )\n",
    "\n",
    "#         return train_loader_list, test_loader\n",
    "\n",
    "#     def __get_mnist(self):\n",
    "#         minist_train_ds = datasets.MNIST(\n",
    "#             \"../data\",\n",
    "#             train=True,\n",
    "#             download=True,\n",
    "#             transform=transforms.Compose(\n",
    "#                 [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "#             ),\n",
    "#         )\n",
    "#         mnist_test_ds = datasets.MNIST(\n",
    "#             \"../data\",\n",
    "#             train=False,\n",
    "#             transform=transforms.Compose(\n",
    "#                 [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "#             ),\n",
    "#         )\n",
    "#         return minist_train_ds, mnist_test_ds\n",
    "\n",
    "#     def __distribute_data_non_IID(self, minist_train_ds):\n",
    "#         digit_sort_idx = np.concatenate(\n",
    "#             [np.where(minist_train_ds.targets == i)[0] for i in range(10)]\n",
    "#         )\n",
    "#         digit_sort_idx = digit_sort_idx.reshape(2 * self.config.N_CLIENTS, -1)\n",
    "#         np.random.shuffle(digit_sort_idx)\n",
    "#         indices = [\n",
    "#             digit_sort_idx[i : i + 2,].flatten()\n",
    "#             for i in range(0, 2 * self.config.N_CLIENTS, 2)\n",
    "#         ]\n",
    "#         return indices\n",
    "#         # TODO return idices and remove the rest\n",
    "#         # dss = []\n",
    "#         # for idx, c in zip(indices, self.clients):\n",
    "#         #     data, target = get_dataset_items_at(minist_train_ds, idx)\n",
    "#         #     dss.append(sy.BaseDataset(data.send(c), target.send(c)))\n",
    "\n",
    "#         # federated_train_dataset = sy.FederatedDataset(dss)\n",
    "#         # return federated_train_dataset\n",
    "\n",
    "#     def build_model(self) -> nn.Module:\n",
    "#         return Net()\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 5, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 5, 1)\n",
    "#         self.fc1 = nn.Linear(4 * 4 * 64, 512)\n",
    "#         self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.max_pool2d(x, 2, 2)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.max_pool2d(x, 2, 2)\n",
    "#         x = x.view(-1, 4 * 4 * 64)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = TorchFederatedLearnerEMNIST(Empty(), TorchFederatedLearnerEMNISTConfig(IS_IID_DATA=False), TorchFederatedLearnerTechnicalConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = lr.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n",
      "(339298, 1, 28, 28) torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "i = next(iter(d[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data, target = next(iter(tr[1]))\n",
    "plt.imshow(data[0, 0, ])\n",
    "print(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_ in list(range(10)):\n",
    "    if f_ not in target.numpy().flatten().tolist():\n",
    "        print(f_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(d) for d in tr]) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(60000).reshape(100, -1)\n",
    "indices = indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l = indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.MNIST(\n",
    "            \"../data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        )\n",
    "ds.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
