{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_ds = datasets.CIFAR10('data/cifar10', download=True) \n",
    "#             transform=transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_file in module tensorflow.python.keras.utils.data_utils:\n",
      "\n",
      "get_file(fname, origin, untar=False, md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', extract=False, archive_format='auto', cache_dir=None)\n",
      "    Downloads a file from a URL if it not already in the cache.\n",
      "    \n",
      "    By default the file at the url `origin` is downloaded to the\n",
      "    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n",
      "    and given the filename `fname`. The final location of a file\n",
      "    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n",
      "    \n",
      "    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n",
      "    Passing a hash will verify the file after download. The command line\n",
      "    programs `shasum` and `sha256sum` can compute the hash.\n",
      "    \n",
      "    Arguments:\n",
      "        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n",
      "            specified the file will be saved at that location.\n",
      "        origin: Original URL of the file.\n",
      "        untar: Deprecated in favor of 'extract'.\n",
      "            boolean, whether the file should be decompressed\n",
      "        md5_hash: Deprecated in favor of 'file_hash'.\n",
      "            md5 hash of the file for verification\n",
      "        file_hash: The expected hash string of the file after download.\n",
      "            The sha256 and md5 hash algorithms are both supported.\n",
      "        cache_subdir: Subdirectory under the Keras cache dir where the file is\n",
      "            saved. If an absolute path `/path/to/folder` is\n",
      "            specified the file will be saved at that location.\n",
      "        hash_algorithm: Select the hash algorithm to verify the file.\n",
      "            options are 'md5', 'sha256', and 'auto'.\n",
      "            The default 'auto' detects the hash algorithm in use.\n",
      "        extract: True tries extracting the file as an Archive, like tar or zip.\n",
      "        archive_format: Archive format to try for extracting the file.\n",
      "            Options are 'auto', 'tar', 'zip', and None.\n",
      "            'tar' includes tar, tar.gz, and tar.bz files.\n",
      "            The default 'auto' is ['tar', 'zip'].\n",
      "            None or an empty list will return no matches found.\n",
      "        cache_dir: Location to store cached files, when None it\n",
      "            defaults to the [Keras\n",
      "              Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n",
      "    \n",
      "    Returns:\n",
      "        Path to the downloaded file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.utils.get_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = tf.keras.utils.get_file(\n",
    "      'fed_cifar100.tar.bz2',\n",
    "      origin='https://storage.googleapis.com/tff-datasets-public/fed_cifar100.tar.bz2',\n",
    "      file_hash='e8575e22c038ecef1ce6c7d492d7abee7da13b1e1ba9b70a7fc18531ba7590de',\n",
    "      hash_algorithm='sha256',\n",
    "      extract=True,\n",
    "      archive_format='tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(path)\n",
    "h5 = h5py.File(os.path.join(dir_path, 'fed_cifar100_test.h5'), \"r\")[\"examples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = h5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar100fed_h5(split):\n",
    "    dir_path = os.path.dirname(get_cifar100fed_h5.path)\n",
    "    return h5py.File(os.path.join(dir_path, f'fed_cifar100_{split}.h5'), \"r\")[\"examples\"]\n",
    "\n",
    "get_cifar100fed_h5.path = tf.keras.utils.get_file(\n",
    "      'fed_cifar100.tar.bz2',\n",
    "      origin='https://storage.googleapis.com/tff-datasets-public/fed_cifar100.tar.bz2',\n",
    "      file_hash='e8575e22c038ecef1ce6c7d492d7abee7da13b1e1ba9b70a7fc18531ba7590de',\n",
    "      hash_algorithm='sha256',\n",
    "      extract=True,\n",
    "      archive_format='tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CIFAR10Fed(Dataset):\n",
    "    N_ELEMENTS_PER_CLIENT = 100\n",
    "    def __init__(self, split, transform=None):\n",
    "        if isinstance(split, str) and split == \"test\":\n",
    "            self.h5 = get_cifar100fed_h5('test')\n",
    "            self.clients = list(self.h5.keys())\n",
    "        else:\n",
    "            self.h5 = get_cifar100fed_h5('train')\n",
    "            self.clients = split\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.clients) * self.N_ELEMENTS_PER_CLIENT\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        client_id = idx // self.N_ELEMENTS_PER_CLIENT\n",
    "        item_id = idx % self.N_ELEMENTS_PER_CLIENT\n",
    "        \n",
    "        client = self.h5[self.clients[client_id]]\n",
    "        img = client[\"image\"][item_id]\n",
    "        label = client[\"label\"][item_id]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CIFAR10Fed('test', transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9608, 0.9608, 0.9922],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9529, 0.9608, 0.9922],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9373, 0.9608, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.8196, 1.0000, 0.9843],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.8275, 1.0000, 0.9843],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.8353, 1.0000, 0.9843]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.7255, 0.9843, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.7725, 0.9922, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.8118, 0.9843, 1.0000]]]), 91)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in h5.keys():\n",
    "    assert len(h5[\"0\"][\"label\"]) == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '2',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '3',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '4',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '5',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '6',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '7',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '8',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '9',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(h5.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "105 // 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarse_label\n",
      "image\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "for k, v in h5[\"examples\"][\"1\"].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  1,   1,   1]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  1,   1,   1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[200, 200, 200],\n",
       "        [201, 201, 201],\n",
       "        [202, 202, 202],\n",
       "        ...,\n",
       "        [195, 195, 195],\n",
       "        [197, 197, 197],\n",
       "        [192, 192, 192]],\n",
       "\n",
       "       [[202, 202, 202],\n",
       "        [204, 204, 204],\n",
       "        [207, 207, 207],\n",
       "        ...,\n",
       "        [197, 197, 197],\n",
       "        [198, 198, 198],\n",
       "        [196, 196, 196]],\n",
       "\n",
       "       [[210, 210, 210],\n",
       "        [212, 212, 212],\n",
       "        [213, 213, 213],\n",
       "        ...,\n",
       "        [193, 193, 193],\n",
       "        [193, 193, 193],\n",
       "        [193, 193, 193]]], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5[\"1\"][\"image\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
