{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCdqejDUf8Ie"
   },
   "source": [
    "# Federated learning\n",
    "\n",
    "Ezen a gyakorlaton egy egyszerű *federated learning* modellt fogunk építeni (szimulálni). Ez annyiban tér el a szokásos felügyelt tanulási sémánktól, hogy a tanítóadatok most közvetlenül nem állnak rendelkezésünkre, hanem elosztott módon, több kliensen helyezkednek el. Kézenfekvő példa lehet egy mobil operációs rendszer autocorrect/autocomplete szolgáltatása, ahol az adatok csak lokálisan, az eszközön érhetők el (pl. korábban begépelt vagy kiválasztott szavak), a predikcióhoz mégis egy közös, kollektív modellt szeretnénk tanulni. A módszer alapötlete, hogy magát a tanulást is a klienseken végezzük; az adatokat nem kell centralizálni, így a kommunikációs overhead elkerülhető, a biztonsági aggályokról nem is beszélve.\n",
    "\n",
    "A gyakorlatban rendszerint a következő történik:\n",
    "- A kliens megkapja az aktuális globális modellt (pl. mély neurális hálózat),\n",
    "- Ezt frissíti a lokális adatok alapján (pl. backpropagation),\n",
    "- A frissítést (pl. új súlyokat) visszaküldi a szervernek megfelelő titkosítás mellett (lásd pl. differential privacy, SecureNN/SPDZ protokollok)\n",
    "- A szerver aggregálja (pl. átlagolja) a beérkezett adatokat és frissíti a globális modellt, amit akár rögtön vissza is küldhet a klienseknek.\n",
    "\n",
    "Ezen a gyakorlaton a biztonsági aspektusokkal nem foglalkozunk, ám más problémák is felmerülnek:\n",
    "- Az egyes klienseken található adatok más-más eloszlást követnek (nem IID)\n",
    "- Az egyes klienseken eltérhet az adatok mennyisége (kiegyensúlyozatlanság)\n",
    "- Technikai problémák: pl. kliensek nagy száma, kommunikációs overhead/sávszélességi korlátok\n",
    "\n",
    "Az általunk használt algoritmus részletei megtalálhatók itt: https://arxiv.org/pdf/1602.05629.pdf (1. algoritmus). Az egyszerűség kedvéért eltekintünk a véletlenszerűen kiválasztott kliensektől, azaz minden frissítésben minden kliens részt fog venni. Szintén az egyszerűség érdekében egy elosztott képklasszfikáló modellt tanulunk a MNIST dataset alapján."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NaO6K3NmA9nK",
    "outputId": "81880312-842d-4383-9fc4-8bf16daa0495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRQxlEeygWRS"
   },
   "source": [
    "**1. feladat.** Hozzon létre egy képklasszifikáló modellt a MNIST adathalmazra! Értékelje ki a prediktív teljesítményt ($>95\\%$)!\n",
    "\n",
    "Példa: https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/convolutional_neural_network/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfBkJ9wNW82h"
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_clients = 10\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3MBeBSsA_aC"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "  def __init__(self, num_classes=10):\n",
    "    super(Model, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "  def forward(self, x):\n",
    "    out = self.layer1(x)\n",
    "    out = self.layer2(out)\n",
    "    out = out.reshape(out.size(0), -1)\n",
    "    out = self.fc(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjYyCFmiC82e"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('../data', train=True, download=True,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ]))\n",
    "test_data = datasets.MNIST('../data', train=False, download=True,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr1YoCUFWz3u"
   },
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=1,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=1,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNiFs_Q_V-tn"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "YHJ4sAgyWlD8",
    "outputId": "c1687fd6-33b3-4d94-ba88-111a60ad96e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2881\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1064\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0402\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0491\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:05<00:20,  5.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [600/600], Loss: 0.0795\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0539\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0402\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0334\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0532\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 2/5 [00:10<00:15,  5.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [600/600], Loss: 0.0626\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0372\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0176\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0535\n",
      "Epoch [3/5], Step [400/600], Loss: 0.1548\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:15<00:10,  5.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [600/600], Loss: 0.0618\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0171\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0113\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0103\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0468\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [00:20<00:05,  5.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Step [600/600], Loss: 0.0052\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0221\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0121\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0089\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0079\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:25<00:00,  5.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [600/600], Loss: 0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K5rChlKQXV6a",
    "outputId": "dce6eae3-04a4-42cb-a887-752aa6057b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.89 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQxm3GeSg01m"
   },
   "source": [
    "**2. feladat.** Hozzon létre egy `TorchClient` osztályt, amely az előbbi architektúrával megegyező neurális hálózatot tartalmaz! Az `__init__()` függvényben valósítson meg egy IID ill. nem IID adatfelbontási sémát (véletlenszerűen szétosztott adatok vs. minden kliens csak egyetlen számjegyet lát). A `train()` függvényben implementálja a tanítást."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3K73YDUhojy"
   },
   "source": [
    "**3. feladat.** Hozzon létre egy `Server` osztályt, ami elvégzi a federált tanítást! Ehhez implementálja az `avg_models` függvényt, valamint a bevezetésben bemutatott algoritmust!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNTBTZHEalZf"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = Model().cuda()\n",
    "    self.loader = torch.utils.data.DataLoader(dataset=test_data)\n",
    "\n",
    "  # Kliens modellek paramétereinek átlagolása, saját modell frissítése\n",
    "  def avg_models(self,clients):\n",
    "    state_dict = {}\n",
    "\n",
    "    parameters = [client.model.state_dict() for client in clients]\n",
    "    with torch.no_grad():\n",
    "        for parameter_name in parameters[0].keys():\n",
    "          state_dict[parameter_name] = torch.mean(\n",
    "              torch.stack(\n",
    "                  [\n",
    "                      model_parameters[parameter_name].float()\n",
    "                      for model_parameters in parameters\n",
    "                  ]\n",
    "              ),\n",
    "              dim=0,\n",
    "          )\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "  def distribute_model(self, clients):\n",
    "    for client in clients:\n",
    "      client.send(self.model)\n",
    "\n",
    "  # Tanítás\n",
    "  def train(self,clients,num_epoch=10):\n",
    "    for i in tqdm(range(num_epoch)):\n",
    "      for client in clients:\n",
    "        client.train(1)\n",
    "      self.avg_models(clients)\n",
    "      self.distribute_model(clients)\n",
    "      self.eval()\n",
    "\n",
    "  # Kiértékelés\n",
    "  def eval(self):\n",
    "    self.model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = self.model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSIxrCWfiLaj"
   },
   "source": [
    "**4. feladat.** Értékelje ki a prediktív teljesítményt az IID és nem IID felállásban, vonjon le következtetéseket!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "UL8t6AxUhF0r",
    "outputId": "36f8cea8-b0e9-406f-ab0e-baef20c4a55a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:56<03:45, 56.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 21.71 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 2/5 [01:52<02:49, 56.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 89.42 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [02:49<01:52, 56.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 92.58 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [03:45<00:56, 56.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 93.69 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [04:41<00:00, 56.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 94.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "clients = [TorchClient(i, iid=True) for i in range(num_clients)]\n",
    "server = Server()\n",
    "server.train(clients, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "HiNSIPXzhDAV",
    "outputId": "74bba041-97a6-4be7-9aab-b291cca9cd4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:58<08:47, 58.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 11.48 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 2/10 [01:57<07:48, 58.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 27.37 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 3/10 [02:55<06:49, 58.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 41.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 4/10 [03:53<05:50, 58.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 45.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 5/10 [04:52<04:52, 58.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 47.4 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 6/10 [05:50<03:53, 58.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 48.79 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 7/10 [06:49<02:55, 58.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 50.86 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 8/10 [07:47<01:56, 58.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 53.98 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 9/10 [08:46<00:58, 58.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 57.09 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [09:44<00:00, 58.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 60.29 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "clients = [TorchClient(i, iid=False) for i in range(num_clients)]\n",
    "server = Server()\n",
    "server.train(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yb5owcHDts4Y"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.multiprocessing import Pool, Process, set_start_method\n",
    "try:\n",
    "     set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "pool = Pool(processes=4)\n",
    "\n",
    "class MultiServer():\n",
    "  def __init__(self):\n",
    "    self.model = Model()#.cuda()\n",
    "    self.loader = torch.utils.data.DataLoader(dataset=test_data)\n",
    "\n",
    "  # Kliens modellek paramétereinek átlagolása, saját modell frissítése\n",
    "  def avg_models(self,clients):\n",
    "    state_dict = {}\n",
    "\n",
    "    parameters = [client.model.state_dict() for client in clients]\n",
    "    with torch.no_grad():\n",
    "        for parameter_name in parameters[0].keys():\n",
    "          state_dict[parameter_name] = torch.mean(\n",
    "              torch.stack(\n",
    "                  [\n",
    "                      model_parameters[parameter_name].float()\n",
    "                      for model_parameters in parameters\n",
    "                  ]\n",
    "              ),\n",
    "              dim=0,\n",
    "          )\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "  def distribute_model(self, clients):\n",
    "    for client in clients:\n",
    "      client.send(self.model)\n",
    "\n",
    "  # Tanítás\n",
    "  def train(self,clients,num_epoch=10):\n",
    "#     f = lambda c: c.train(1)\n",
    "    self.model.share_memory()\n",
    "    for i in tqdm(range(num_epoch)):\n",
    "      clients = pool.map(f, zip(clients, [self.model] * len(clients)))\n",
    "      self.avg_models(clients)\n",
    "#       self.distribute_model(clients)\n",
    "      self.eval()\n",
    "\n",
    "  # Kiértékelés\n",
    "  def eval(self):\n",
    "    self.model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = self.model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "def f(c, m):\n",
    "    c.send(m)\n",
    "    return c.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQH3sk7dU4wg"
   },
   "outputs": [],
   "source": [
    "class TorchClient():\n",
    "  def __init__(self,id,iid=True):\n",
    "    self.id = id\n",
    "#     self.model = Model().cuda()\n",
    "\n",
    "    num_samples_per_client = len(train_data) // num_clients\n",
    "    if iid:\n",
    "      all_idx = np.arange(len(train_data.targets))\n",
    "      # np.random.shuffle(all_idx)\n",
    "      pass\n",
    "    else:\n",
    "      all_idx = np.argsort(train_data.targets)\n",
    "    idx = all_idx[self.id*num_samples_per_client:(self.id + 1)*num_samples_per_client]\n",
    "      \n",
    "    sampler = torch.utils.data.sampler.SubsetRandomSampler(idx)\n",
    "    self.loader = torch.utils.data.DataLoader(dataset=train_data,batch_size=256,sampler=sampler)\n",
    "    self.loss   = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  def train(self,num_epoch):\n",
    "    self.opt = torch.optim.SGD(self.model.parameters(),lr=0.001)\n",
    "    total_step = len(self.loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(self.loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                      .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    return self\n",
    "\n",
    "  # Kapott modell átmásolása\n",
    "  def send(self,model):\n",
    "    self.model = Model().cuda()\n",
    "    self.model.load_state_dict(model.state_dict())\n",
    "#     self.model.share_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# original\n",
    "clients = [TorchClient(i, iid=False) for i in range(num_clients)]\n",
    "server = MultiServer()\n",
    "server.train(clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fat proxy, Bayesian. MIT/en van valami FL-es ucc."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of KGT-Federated-PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
