{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qN8P0AnTnAhh"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "p8SrVqkmnDQv"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "height": 120
    },
    "colab_type": "code",
    "id": "8BKyHkMxKHfV",
    "outputId": "9996c409-f96d-45b6-ef88-34fcf3c3b589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NayDhCX6SjwE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tff-datasets-public/fed_emnist_digitsonly.tar.bz2\n",
      "97402880/97398400 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "height": 33
    },
    "colab_type": "code",
    "id": "ZyCzIrSegT62",
    "outputId": "b10af36c-2e0d-4188-8aed-11413b824e10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)),\n",
       "             ('pixels',\n",
       "              TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emnist_train.element_type_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "height": 33
    },
    "colab_type": "code",
    "id": "EsvSXGEMgd9G",
    "outputId": "85dce10c-97a1-40d3-e576-6f20d294959a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "    emnist_train.client_ids[0])\n",
    "\n",
    "example_element = iter(example_dataset).next()\n",
    "\n",
    "example_element['label'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "height": 268
    },
    "colab_type": "code",
    "id": "OmLV0nfMg98V",
    "outputId": "185fcef6-fc6f-4892-cb5c-3eff704aeda1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
    "plt.grid('off')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMd01egqy9we"
   },
   "source": [
    "Since the data is already a `tf.data.Dataset`,  preprocessing can be accomplished using Dataset transformations. Here, we flatten the `28x28` images\n",
    "into `784`-element arrays, shuffle the individual examples, organize them into batches, and renames the features\n",
    "from `pixels` and `label` to `x` and `y` for use with Keras. We also throw in a\n",
    "`repeat` over the data set to run several epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyG_BMraSuu_"
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10 #len(emnist_train.client_ids)\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 500\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def element_fn(element):\n",
    "    return collections.OrderedDict([\n",
    "        ('x', tf.reshape(element['pixels'], [-1])),\n",
    "        ('y', tf.reshape(element['label'], [1])),\n",
    "    ])\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).map(element_fn).shuffle(\n",
    "      SHUFFLE_BUFFER).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9LXykN_jlJw"
   },
   "source": [
    "Let's verify this worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "height": 450
    },
    "colab_type": "code",
    "id": "VChB7LMQjkYz",
    "outputId": "07554b9e-7e5b-49a4-bf4f-88c33b1d29ca"
   },
   "outputs": [],
   "source": [
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(\n",
    "    lambda x: x.numpy(), iter(preprocessed_example_dataset).next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_PHMvHAI9xVc"
   },
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "  return [preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "          for x in client_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "height": 50
    },
    "colab_type": "code",
    "id": "GZ6NYHxB8xer",
    "outputId": "66f4a68d-a20f-43b1-d2d1-75b89d7080f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3383,\n",
       " <BatchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
    "\n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "len(federated_train_data), federated_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['x'][0].reshape((28, 28)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOxq4tbi9m8-"
   },
   "source": [
    "## Creating a model with Keras\n",
    "\n",
    "If you are using Keras, you likely already have code that constructs a Keras\n",
    "model. Here's an example of a simple model that will suffice for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYCsJGJFWbqt"
   },
   "outputs": [],
   "source": [
    "def create_compiled_keras_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          10, activation=tf.nn.softmax, kernel_initializer='zeros', input_shape=(784,))])\n",
    "  \n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3ynrxd53HzY"
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "  keras_model = create_compiled_keras_model()\n",
    "  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sk6mjOfycX5N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "height": 33
    },
    "colab_type": "code",
    "id": "Z4pcfWsUBp_5",
    "outputId": "c1b46970-c528-49c7-d356-95f98e99c62a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cagCWlZmcch"
   },
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjjxTx9e_rMd"
   },
   "source": [
    "The second of the pair of federated computations, `next`, represents a single\n",
    "round of Federated Averaging, which consists of pushing the server state\n",
    "(including the model parameters) to the clients, on-device training on their\n",
    "local data, collecting and averaging model updates, and producing a new updated\n",
    "model at the server.\n",
    "\n",
    "Conceptually, you can think of `next` as having a functional type signature that\n",
    "looks as follows.\n",
    "\n",
    "```\n",
    "SERVER_STATE, FEDERATED_DATA -> SERVER_STATE, TRAINING_METRICS\n",
    "```\n",
    "\n",
    "In particular, one should think about `next()` not as being a function that runs on a server, but rather being a declarative functional representation of the entire decentralized computation - some of the inputs are provided by the server (`SERVER_STATE`), but each participating device contributes its own local dataset.\n",
    "\n",
    "Let's run a single round of training and visualize the results. We can use the\n",
    "federated data we've already generated above for a sample of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 33
    },
    "colab_type": "code",
    "id": "F3M_W9dDE6Tm",
    "outputId": "d09e8280-b372-4d6a-9a1b-7b4dec41edb8"
   },
   "outputs": [],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_federated.python.common_libs.anonymous_tuple.AnonymousTuple"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.14578189, 'keras_training_time_client_sum_sec'),\n",
       " (2.97196, 'loss'),\n",
       " (0.000600338, 'sparse_categorical_accuracy')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(metrics, dir(metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras_training_time_client_sum_sec: 0.0006003379821777344\n",
      "loss: 2.9719600677490234\n",
      "sparse_categorical_accuracy: 0.14578188955783844\n"
     ]
    }
   ],
   "source": [
    "for name in dir(metrics):\n",
    "    print(f\"{name}: {getattr(metrics, name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14578189"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics.\n",
    "getattr(metrics, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "height": 166
    },
    "colab_type": "code",
    "id": "qrJkQuCRJP9C",
    "outputId": "f069e613-c38e-4cfa-fd1c-47d44207cddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=<sparse_categorical_accuracy=0.18065842986106873,loss=2.775916337966919,keras_training_time_client_sum_sec=0.0006308555603027344>\n",
      "round  3, metrics=<sparse_categorical_accuracy=0.22211934626102448,loss=2.4514782428741455,keras_training_time_client_sum_sec=0.0006222724914550781>\n",
      "round  4, metrics=<sparse_categorical_accuracy=0.27407407760620117,loss=2.2914140224456787,keras_training_time_client_sum_sec=0.0006554126739501953>\n",
      "round  5, metrics=<sparse_categorical_accuracy=0.32695472240448,loss=2.0907809734344482,keras_training_time_client_sum_sec=0.0007643699645996094>\n",
      "round  6, metrics=<sparse_categorical_accuracy=0.39907407760620117,loss=1.8560289144515991,keras_training_time_client_sum_sec=0.0006082057952880859>\n",
      "round  7, metrics=<sparse_categorical_accuracy=0.44876542687416077,loss=1.7270830869674683,keras_training_time_client_sum_sec=0.0007834434509277344>\n",
      "round  8, metrics=<sparse_categorical_accuracy=0.4834362268447876,loss=1.5978162288665771,keras_training_time_client_sum_sec=0.0006067752838134766>\n",
      "round  9, metrics=<sparse_categorical_accuracy=0.499176949262619,loss=1.5160000324249268,keras_training_time_client_sum_sec=0.0006036758422851562>\n",
      "round 10, metrics=<sparse_categorical_accuracy=0.5403292179107666,loss=1.4522349834442139,keras_training_time_client_sum_sec=0.0006196498870849609>\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 11\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "joHYzn9jcs0Y"
   },
   "source": [
    "Training loss is decreasing after each round of federated training, indicating\n",
    "the model is converging. There are some important caveats with these training\n",
    "metrics, however, see the section on *Evaluation* later in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruSHJl1IjhNf"
   },
   "source": [
    "## Displaying model metrics in TensorBoard\n",
    "Next, let's visualize the metrics from these federated computations using Tensorboard.\n",
    "\n",
    "Let's start by creating the directory and the corresponding summary writer to write the metrics to.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3QUBK41lWDW"
   },
   "outputs": [],
   "source": [
    "# #@test {\"skip\": true}\n",
    "# logdir = \"/tmp/logs/scalars/training/\"\n",
    "# summary_writer = tf.summary.create_file_writer(logdir)\n",
    "# state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-2aGxUlzS_J"
   },
   "source": [
    "Plot the relevant scalar metrics with the same summary writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZtr4_8lzN-V"
   },
   "outputs": [],
   "source": [
    "# #@test {\"skip\": true}\n",
    "# with summary_writer.as_default():\n",
    "#   for round_num in range(1, NUM_ROUNDS):\n",
    "#     state, metrics = iterative_process.next(state, federated_train_data)\n",
    "#     for name, value in metrics._asdict().items():\n",
    "#       tf.compat.v2.summary.scalar(name, value, step=round_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUouyAHG0Mk8"
   },
   "source": [
    "Start TensorBoard with the root log directory specified above. It can take a few seconds for the data to load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jejrFEVP1EDs"
   },
   "source": [
    "In order to view evaluation metrics the same way, you can create a separate eval folder, like \"logs/scalars/eval\", to write to TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4hneAcb-F2l"
   },
   "source": [
    "## Customizing the model implementation\n",
    "\n",
    "Keras is the [recommended high-level model API for TensorFlow](https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a), and we encourage using Keras models (via \n",
    "`tff.learning.from_keras_model` or\n",
    "`tff.learning.from_compiled_keras_model`) in TFF whenever possible.\n",
    "\n",
    "However, `tff.learning` provides a lower-level model interface, `tff.learning.Model`, that exposes the minimal functionality necessary for using a model for federated learning. Directly implementing this interface (possibly still using building blocks like `tf.keras.layers`) allows for maximum customization without modifying the internals of the federated learning algorithms.\n",
    "\n",
    "So let's do it all over again from scratch.\n",
    "\n",
    "### Defining model variables, forward pass, and metrics\n",
    "\n",
    "The first step is to identify the TensorFlow variables we're going to work with.\n",
    "In order to make the following code more legible, let's define a data structure\n",
    "to represent the entire set. This will include variables such as `weights` and\n",
    "`bias` that we will train, as well as variables that will hold various\n",
    "cumulative statistics and counters we will update during training, such as\n",
    "`loss_sum`, `accuracy_sum`, and `num_examples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqRD72WQC4u1"
   },
   "outputs": [],
   "source": [
    "MnistVariables = collections.namedtuple(\n",
    "    'MnistVariables', 'weights bias num_examples loss_sum accuracy_sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkJfDcY5oXii"
   },
   "source": [
    "Here's a method that creates the variables. For the sake of simplicity, we\n",
    "represent all statistics as `tf.float32`, as that will eliminate the need for\n",
    "type conversions at a later stage. Wrapping variable initializers as lambdas is\n",
    "a requirement imposed by\n",
    "[resource variables](https://www.tensorflow.org/api_docs/python/tf/enable_resource_variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3GQHLNqCfMU"
   },
   "outputs": [],
   "source": [
    "def create_mnist_variables():\n",
    "  return MnistVariables(\n",
    "      weights = tf.Variable(\n",
    "          lambda: tf.zeros(dtype=tf.float32, shape=(784, 10)),\n",
    "          name='weights',\n",
    "          trainable=True),\n",
    "      bias = tf.Variable(\n",
    "          lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n",
    "          name='bias',\n",
    "          trainable=True),\n",
    "      num_examples = tf.Variable(0.0, name='num_examples', trainable=False),\n",
    "      loss_sum = tf.Variable(0.0, name='loss_sum', trainable=False),\n",
    "      accuracy_sum = tf.Variable(0.0, name='accuracy_sum', trainable=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SrdnR0fAre-Q"
   },
   "source": [
    "With the variables for model parameters and cumulative statistics in place, we\n",
    "can now define the forward pass method that computes loss, emits predictions,\n",
    "and updates the cumulative statistics for a single batch of input data, as\n",
    "follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYSRAl-KCvC7"
   },
   "outputs": [],
   "source": [
    "def mnist_forward_pass(variables, batch):\n",
    "  y = tf.nn.softmax(tf.matmul(batch['x'], variables.weights) + variables.bias)\n",
    "  predictions = tf.cast(tf.argmax(y, 1), tf.int32)\n",
    "\n",
    "  flat_labels = tf.reshape(batch['y'], [-1])\n",
    "  loss = -tf.reduce_mean(tf.reduce_sum(\n",
    "      tf.one_hot(flat_labels, 10) * tf.math.log(y), axis=[1]))\n",
    "  accuracy = tf.reduce_mean(\n",
    "      tf.cast(tf.equal(predictions, flat_labels), tf.float32))\n",
    "\n",
    "  num_examples = tf.cast(tf.size(batch['y']), tf.float32)\n",
    "\n",
    "  variables.num_examples.assign_add(num_examples)\n",
    "  variables.loss_sum.assign_add(loss * num_examples)\n",
    "  variables.accuracy_sum.assign_add(accuracy * num_examples)\n",
    "\n",
    "  return loss, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-gm-yx2Mr_bl"
   },
   "source": [
    "Next, we define a function that returns a set of local metrics, again using TensorFlow. These are the values (in addition to model updates, which are handled automatically) that are eligible to be aggregated to the server in a federated learning or evaluation process.\n",
    "\n",
    "Here, we simply return the average `loss` and `accuracy`, as well as the\n",
    "`num_examples`, which we'll need to correctly weight the contributions from\n",
    "different users when computing federated aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkAZXhjGEekp"
   },
   "outputs": [],
   "source": [
    "def get_local_mnist_metrics(variables):\n",
    "  return collections.OrderedDict([\n",
    "      ('num_examples', variables.num_examples),\n",
    "      ('loss', variables.loss_sum / variables.num_examples),\n",
    "      ('accuracy', variables.accuracy_sum / variables.num_examples)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ywGs1G-s1o3"
   },
   "source": [
    "Finally, we need to determine how to aggregate the local metrics emitted by each\n",
    "device via `get_local_mnist_metrics`. This is the only part of the code that isn't written in TensorFlow  - it's a *federated computation* expressed in TFF. If you'd like to\n",
    "dig deeper, skim over the [custom algorithms](custom_federated_algorithms_1.ipynb)\n",
    "tutorial, but in most applications, you won't really need to; variants of the\n",
    "pattern shown below should suffice. Here's what it looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMr2PwkfExFI"
   },
   "outputs": [],
   "source": [
    "@tff.federated_computation\n",
    "def aggregate_mnist_metrics_across_clients(metrics):\n",
    "  return {\n",
    "      'num_examples': tff.federated_sum(metrics.num_examples),\n",
    "      'loss': tff.federated_mean(metrics.loss, metrics.num_examples),\n",
    "      'accuracy': tff.federated_mean(metrics.accuracy, metrics.num_examples)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rXZ3Hg44aeN"
   },
   "source": [
    "The input `metrics` argument corresponds to the `OrderedDict` returned by `get_local_mnist_metrics` above, but critically the values are no longer `tf.Tensors` - they are \"boxed\" as `tff.Value`s, to make it clear you can no longer manipulate them using TensorFlow, but only using TFF's federated operators like `tff.federated_mean` and `tff.federated_sum`.  The returned\n",
    "dictionary of global aggregates defines the set of metrics which will be available on the server.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MXGAuQRvmcp"
   },
   "source": [
    "### Constructing an instance of `tff.learning.Model`\n",
    "\n",
    "With all of the above in place, we are ready to construct a model representation\n",
    "for use with TFF similar to one that's generated for you when you let TFF ingest\n",
    "a Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blQGiTQFS9_r"
   },
   "outputs": [],
   "source": [
    "class MnistModel(tff.learning.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    self._variables = create_mnist_variables()\n",
    "\n",
    "  @property\n",
    "  def trainable_variables(self):\n",
    "    return [self._variables.weights, self._variables.bias]\n",
    "\n",
    "  @property\n",
    "  def non_trainable_variables(self):\n",
    "    return []\n",
    "\n",
    "  @property\n",
    "  def local_variables(self):\n",
    "    return [\n",
    "        self._variables.num_examples, self._variables.loss_sum,\n",
    "        self._variables.accuracy_sum\n",
    "    ]\n",
    "\n",
    "  @property\n",
    "  def input_spec(self):\n",
    "    return collections.OrderedDict([('x', tf.TensorSpec([None, 784],\n",
    "                                                        tf.float32)),\n",
    "                                    ('y', tf.TensorSpec([None, 1], tf.int32))])\n",
    "\n",
    "  @tf.function\n",
    "  def forward_pass(self, batch, training=True):\n",
    "    del training\n",
    "    loss, predictions = mnist_forward_pass(self._variables, batch)\n",
    "    num_exmaples = tf.shape(batch['x'])[0]\n",
    "    return tff.learning.BatchOutput(\n",
    "        loss=loss, predictions=predictions, num_examples=num_exmaples)\n",
    "\n",
    "  @tf.function\n",
    "  def report_local_outputs(self):\n",
    "    return get_local_mnist_metrics(self._variables)\n",
    "\n",
    "  @property\n",
    "  def federated_output_computation(self):\n",
    "    return aggregate_mnist_metrics_across_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMN1AszMwLHL"
   },
   "source": [
    "As you can see, the abstract methods and properties defined by\n",
    "`tff.learning.Model` corresponds to the code snippets in the preceding section\n",
    "that introduced the variables and defined the loss and statistics.\n",
    "\n",
    "Here are a few points worth highlighting:\n",
    "\n",
    "*   All state that your model will use must be captured as TensorFlow variables,\n",
    "    as TFF does not use Python at runtime (remember your code should be written\n",
    "    such that it can be deployed to mobile devices; see the\n",
    "    [custom algorithms](custom_federated_algorithms_1.ipynb) tutorial for a more\n",
    "    in-depth commentary on the reasons).\n",
    "*   Your model should describe what form of data it accepts (`input_spec`), as\n",
    "    in general, TFF is a strongly-typed environment and wants to determine type\n",
    "    signatures for all components. Declaring the format of your model's input is\n",
    "    an essential part of it.\n",
    "*   Although technically not required, we recommend wrapping all TensorFlow\n",
    "    logic (forward pass, metric calculations, etc.) as `tf.function`s,\n",
    "    as this helps ensure the TensorFlow can be serialized, and removes the need\n",
    "    for explicit control dependencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DVhXk2Bu-GU"
   },
   "source": [
    "The above is sufficient for evaluation and algorithms like Federated SGD.\n",
    "However, for Federated Averaging, we need to specify how the model should train\n",
    "locally on each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1w7US3PFN2p"
   },
   "outputs": [],
   "source": [
    "class MnistTrainableModel(MnistModel, tff.learning.TrainableModel):\n",
    "\n",
    "  @tf.function\n",
    "  def train_on_batch(self, batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "      output = self.forward_pass(batch)\n",
    "    grads = tape.gradient(output.loss, self.trainable_variables)\n",
    "    optimizer = tf.keras.optimizers.SGD(0.02)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(tf.nest.flatten(grads), tf.nest.flatten(self.trainable_variables)))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hVBugKP3yw03"
   },
   "source": [
    "### Simulating federated training with the new model\n",
    "\n",
    "With all the above in place, the remainder of the process looks like what we've\n",
    "seen already - just replace the model constructor with the constructor of our\n",
    "new model class, and use the two federated computations in the iterative process\n",
    "you created to cycle through training rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FK3c8_leS9_t"
   },
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    MnistTrainableModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jv_LiggwS9_u"
   },
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "height": 33
    },
    "colab_type": "code",
    "id": "PtOLElmzDPxs",
    "outputId": "d9dacd90-d34c-48af-ba45-f018263562fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=<accuracy=0.13456790149211884,loss=3.055020332336426,num_examples=9720.0>\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "height": 166
    },
    "colab_type": "code",
    "id": "gFkv0yJEGhue",
    "outputId": "0b850c24-5529-46d2-ea55-732e5e9adee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=<accuracy=0.18220163881778717,loss=2.7607266902923584,num_examples=9720.0>\n",
      "round  3, metrics=<accuracy=0.22520576417446136,loss=2.4871532917022705,num_examples=9720.0>\n",
      "round  4, metrics=<accuracy=0.26141974329948425,loss=2.3252267837524414,num_examples=9720.0>\n",
      "round  5, metrics=<accuracy=0.3150205910205841,loss=2.1009483337402344,num_examples=9720.0>\n",
      "round  6, metrics=<accuracy=0.37109053134918213,loss=1.9115700721740723,num_examples=9720.0>\n",
      "round  7, metrics=<accuracy=0.4364197552204132,loss=1.767581582069397,num_examples=9720.0>\n",
      "round  8, metrics=<accuracy=0.47417694330215454,loss=1.6142067909240723,num_examples=9720.0>\n",
      "round  9, metrics=<accuracy=0.5333333611488342,loss=1.4666272401809692,num_examples=9720.0>\n",
      "round 10, metrics=<accuracy=0.5591563582420349,loss=1.3803861141204834,num_examples=9720.0>\n"
     ]
    }
   ],
   "source": [
    "for round_num in range(2, 11):\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iswqa2Uj7phq"
   },
   "source": [
    "To see these metrics within TensorBoard, refer to the steps listed above in \"Displaying model metrics in TensorBoard\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m7lz59lMJ0kj"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "All of our experiments so far presented only federated training metrics - the\n",
    "average metrics over all batches of data trained across all clients in the\n",
    "round. This introduces the normal concerns about overfitting, especially since\n",
    "we used the same set of clients on each round for simplicity, but there is an\n",
    "additional notion of overfitting in training metrics specific to the Federated\n",
    "Averaging algorithm. This is easiest to see if we imagine each client had a\n",
    "single batch of data, and we train on that batch for many iterations (epochs).\n",
    "In this case, the local model will quickly exactly fit to that one batch, and so\n",
    "the local accuracy metric we average will approach 1.0. Thus, these training\n",
    "metrics can be taken as a sign that training is progressing, but not much more.\n",
    "\n",
    "To perform evaluation on federated data, you can construct another *federated\n",
    "computation* designed for just this purpose, using the\n",
    "`tff.learning.build_federated_evaluation` function, and passing in your model\n",
    "constructor as an argument. Note that unlike with Federated Averaging, where\n",
    "we've used `MnistTrainableModel`, it suffices to pass the `MnistModel`.\n",
    "Evaluation doesn't perform gradient descent, and there's no need to construct\n",
    "optimizers.\n",
    "\n",
    "For experimentation and research, when a centralized test dataset is available,\n",
    "[Federated Learning for Text Generation](federated_learning_for_text_generation.ipynb)\n",
    "demonstrates another evaluation option: taking the trained weights from\n",
    "federated learning, applying them to a standard Keras model, and then simply\n",
    "calling `tf.keras.models.Model.evaluate()` on a centralized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRiXyqnXM2VO"
   },
   "outputs": [],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(MnistModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwfINGoNQEuV"
   },
   "source": [
    "You can inspect the abstract type signature of the evaluation function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "height": 33
    },
    "colab_type": "code",
    "id": "3q5ueoO0NDNb",
    "outputId": "ade202d2-7dba-41c7-b63b-f9a28e694832"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<<trainable=<float32[784,10],float32[10]>,non_trainable=<>>@SERVER,{<x=float32[?,784],y=int32[?,1]>*}@CLIENTS> -> <accuracy=float32@SERVER,loss=float32@SERVER,num_examples=float32@SERVER>)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(evaluation.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XA3v7f2SQs6q"
   },
   "source": [
    "No need to be concerned about the details at this point, just be aware that it\n",
    "takes the following general form, similar to `tff.utils.IterativeProcess.next`\n",
    "but with two important differences. First, we are not returning server state,\n",
    "since evaluation doesn't modify the model or any other aspect of state - you can\n",
    "think of it as stateless. Second, evaluation only needs the model, and doesn't\n",
    "require any other part of server state that might be associated with training,\n",
    "such as optimizer variables.\n",
    "\n",
    "```\n",
    "SERVER_MODEL, FEDERATED_DATA -> TRAINING_METRICS\n",
    "```\n",
    "\n",
    "Let's invoke evaluation on the latest state we arrived at during training. In\n",
    "order to extract the latest trained model from the server state, you simply\n",
    "access the `.model` member, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX4Sk_uyOaYa"
   },
   "outputs": [],
   "source": [
    "train_metrics = evaluation(state.model, federated_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeEsdwJgRGMW"
   },
   "source": [
    "Here's what we get. Note the numbers look marginally better than what was\n",
    "reported by the last round of training above. By convention, the training\n",
    "metrics reported by the iterative training process generally reflect the\n",
    "performance of the model at the beginning of the training round, so the\n",
    "evaluation metrics will always be one step ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "height": 33
    },
    "colab_type": "code",
    "id": "zwCy1IPxOfiT",
    "outputId": "a6be11ad-8498-425f-ac61-b044cabc0cc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<accuracy=0.7355967164039612,loss=1.1525417566299438,num_examples=9720.0>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SpfgdNDoRjPy"
   },
   "source": [
    "Now, let's compile a test sample of federated data and rerun evaluation on the\n",
    "test data. The data will come from the same sample of real users, but from a\n",
    "distinct held-out data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "height": 50
    },
    "colab_type": "code",
    "id": "in8vProVNc04",
    "outputId": "da625d4f-28e6-49d5-eb5a-726c9bf83040"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " <BatchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated_test_data = make_federated_data(emnist_test, sample_clients)\n",
    "\n",
    "len(federated_test_data), federated_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ty-ZwfE0NJfV"
   },
   "outputs": [],
   "source": [
    "test_metrics = evaluation(state.model, federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "height": 33
    },
    "colab_type": "code",
    "id": "e5fGtIJYNqYH",
    "outputId": "f0e2dceb-3446-430e-d8ab-f6f70dd7d492"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<accuracy=0.6896551847457886,loss=1.2701549530029297,num_examples=1160.0>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67vYxrDWzRcj"
   },
   "source": [
    "This concludes the tutorial. We encourage you to play with the\n",
    "parameters (e.g., batch sizes, number of users, epochs, learning rates, etc.), to modify the code above to simulate training on random samples of users in\n",
    "each round, and to explore the other tutorials we've developed."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Federated Learning for Image Classification",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
